---
title: "p8105_hw3_jg5038"
author: "Julia Gray"
date: "2025-10-02"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(patchwork)
library(p8105.datasets)


knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


# Problem 1

```{r}
data("instacart")

instacart_df = instacart |> 
  janitor::clean_names()

#order_dow is given as an integer but to make it human readable let's change it to a string. We don't know which day is which but in order to find out we can see the distribution by day and assume that the most orders happen on Saturday and Sunday

instacart_df |> 
  group_by(order_dow) |> 
  summarize(n = n_distinct(order_id))

#Let's assume that people order the most groceries on Monday so dow 0 = Monday

instacart_df = instacart_df |> 
  mutate(order_dow_string = 
         case_match(
           order_dow, 
           0 ~ "Mon", 
           1 ~ "Tues",
           2 ~ "Weds",
           3 ~ "Thurs", 
           4 ~ "Fri",
           5 ~ "Sat",
           6 ~ "Sun"
         ))

```

This dataset contains order information from instacart. It is organized by order and contains information about the products ordered, as well as information about the customer (i.e. how long it's been since they last ordered). It contains `r dim(instacart)[1]` observations and includes columns for `r colnames(instacart)`. For example, the first order in the dataset was made by `r unique(select(filter(instacart, order_id==1), user_id))` at `r unique(select(filter(instacart, order_id==1), order_hour_of_day))` o clock and we can see they ordered `r toString(select(filter(instacart, order_id==1), product_name))` (of which `r toString(select(filter(instacart, order_id==1, reordered==1), product_name))` were reordered).

There are `r dim(unique(select(instacart, aisle)))[1]` unique aisles. Here is a table of the aisles most ordered from (just showing the top 10):

```{r}
instacart_aisle_sum_df = instacart_df |> 
  group_by(aisle) |> 
  summarize(
    n = n()
  ) |> 
  arrange(desc(n)) 

instacart_aisle_sum_df |> 
  head(10) |> 
  knitr::kable()
```

Now let's plot aisles with more than 10,000 items ordered from them:

```{r fig.width=6, fig.height=4}
#UPDATE labels and size to render correctly
instacart_aisle_sum_df |> 
  filter(n >= 10000) |> 
  ggplot(aes(x=reorder(aisle, n), y=n)) +
  geom_bar(stat="identity") +
  coord_flip()
```

In order to find the most popular items for each aisle let's group by:

```{r}
instacart_aisle_item_df = instacart_df |> 
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(
    item_aisle_rank = min_rank(desc(n))
    ) |> 
  filter(aisle %in% c('baking ingredients', 'dog food care', 'packaged vegetables fruits'), item_aisle_rank <= 3) |> 
  arrange(aisle, item_aisle_rank)

knitr::kable(instacart_aisle_item_df)
```

To make a table showing the mean hour per day at which items are ordered for each day of the week we will group by day and calculate the mean:

```{r}
instacart_df |> 
  filter(product_name %in% c('Pink Lady Apples', 'Coffee Ice Cream')) |> 
  group_by (product_name, order_dow_string) |> 
  summarize(
    mean_order_hour_of_day = round(mean(order_hour_of_day, na.rm = TRUE), digits=2)
  ) |> 
  pivot_wider(
    names_from = order_dow_string,
    values_from = mean_order_hour_of_day
  ) |> 
  select('product_name', 'Mon', 'Tues', 'Weds', 'Thurs', 'Fri', 'Sat', 'Sun') |> 
  knitr::kable()
```

# Problem 2

Import and tidy data
```{r}
zip_df = read_csv(file="./data/zillow_data/Zip Codes.csv") |> 
  janitor::clean_names()

rent_df = read_csv(file="./data/zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  janitor::clean_names() |> 
  #update column names to match zip_df
  rename(
    zip_code = region_name,
    county = county_name) |> 
  mutate(
    county = str_replace(county, " County", ""),
    borough = 
      case_match(
        county, 
        "Bronx" ~ "Bronx", 
        "Kings" ~ "Brooklyn",
        "New York" ~ "Manhattan",
        "Queens" ~ "Queens", 
        "Richmond" ~ "Staten Island") 
  ) |> 
  pivot_longer(
    cols=x2015_01_31:x2024_08_31,
    names_to = "date",
    values_to="observed_rent_index"
  ) |> 
  mutate(
    #let's use the lubridate package
    date = ymd(str_replace(date, "x", "")),
    year = year(date),
    month = month(date)
  )

rent_zip_df = left_join(rent_df, zip_df, by = c("county", "zip_code")) |> 
  relocate("zip_code", "neighborhood",  "date", "observed_rent_index")
```

How many zipcodes are observed for all 116 months, how many observed less than 10 times?

```{r}
rent_zip_na = rent_zip_df |> 
  group_by(zip_code) |> 
  summarize(
    n_observations = sum(!is.na(observed_rent_index))
  )
```

There are `r dim(filter(rent_zip_na, n_observations==116))[1]` zipcodes with 116 observations and `r dim(filter(rent_zip_na, n_observations<10))[1]` with less than 10. The zipcodes with 116 observations are popular residential districts and the ones with less than 10 are mixed between residential and commercial real estate (for example 10044 is Roosevelt Island). 

```{r}
rent_zip_df |> 
  group_by(borough, year) |> 
  summarize(
    average_rent_index = round(mean(observed_rent_index, na.rm = TRUE), digits=2)
  ) |> 
  pivot_wider(
    names_from = year,
    values_from = average_rent_index
  ) |> 
  knitr::kable()
```

Unsurprisingly, Manhattan has the highest average rent index. There is no data for Staten Island prior to 2020. We can see the decrease caused by COVID across the other bouroughs.

```{r}
year_rent_graph = rent_zip_df |> 
  group_by(zip_code, borough, year) |> 
  summarize(
    average_rent_index = round(mean(observed_rent_index, na.rm = TRUE), digits=2)
  ) |> 
  ggplot(aes(x = year, y=average_rent_index, color=borough)) + 
  geom_point(alpha = 0.5) +
  geom_smooth(se = FALSE) + 
  #geom_boxplot()
  facet_grid(. ~ borough)

year_rent_graph
```

We can see Manhattan, in addition to having the highest average rent index, has the highest variance among all boroughs. 

Let's see some boxplots for Manhattan for fun:

```{r}
rent_zip_df |> 
  filter(borough == 'Manhattan') |> 
  group_by(zip_code, year) |> 
  ggplot(aes(x = year, y=observed_rent_index, group = year)) +
  geom_boxplot()
```

```{r}
#since each row is already 1 zipcode per month there is nothing to average, it will just be the rent index in the row. We can confirm this because when we calculate the mean it is the same as if we just filtered and grouped by (since the n is 1).
month_rent_graph = rent_zip_df |>
  filter(year == 2023) |> 
  group_by(zip_code, borough, month) |> 
  summarize(
    average_rent_index = round(mean(observed_rent_index, na.rm = TRUE), digits=2)
  ) |> 
  ggplot(aes(x = month, y=average_rent_index, color=borough, group=month)) +
  #geom_point() +
  geom_boxplot() +
  facet_grid(. ~ borough)

month_rent_graph
```

Combine the two graphs:

```{r}
year_rent_graph / month_rent_graph + plot_layout(guide="collect")
ggsave('plots/zillow_rent_index_by_borough.pdf')
```

# Problem 3

Load, tidy, merge the dataset

```{r}
accel_df = read.csv('./data/nhanes/nhanes_accel.csv') |> 
  janitor::clean_names() |> 
  #use colnames(accel_df)[ncol(accel_df)] to get last colname
  pivot_longer(
    cols=min1:min1440,
    names_to = "min",
    #names_prefix("min"),
    values_to="MIMS"
  ) |> 
  mutate (
    min = as.integer(str_remove(min, "min"))
  )

#sex: 2 = female
#education: 1 = less than highschool, 2 = high school, 3 = more than highschool
covar_df = read.csv('./data/nhanes/nhanes_covar.csv', skip = 4) |> 
  #let's exlcude participants under 21, or missing demographic data before we merge
  janitor::clean_names() |> 
  filter(age >= 21, !is.na(sex), !is.na(bmi), !is.na(education)) |> 
  mutate(
    sex = case_match(
      sex, 
      1 ~ "male",
      2 ~ "female"
    ),
    education_factor = factor(
      education, 
      levels = c(1, 2, 3),
      labels = c("less than highschool", "highschool", "more than highschool")
    )
  )

nhanes_df = left_join(covar_df, accel_df, by="seqn")
```

Let's produce a reader-friendly table for the number of men and women in each education category

```{r}
nhanes_df |> 
  group_by(sex, education_factor) |> 
  summarize(
    n = n_distinct(seqn)
  ) |> 
  pivot_wider(
    names_from = education_factor,
    values_from = n
  ) |> 
  knitr::kable()
```

Create vizualization of age distribution for men and women in each age category

```{r}
nhanes_df |> 
  select(seqn, sex, age, education_factor) |> 
  distinct() |> 
  ggplot(aes(x=age, color=sex)) +
  geom_histogram(aes(fill=sex), binwidth=5) +
  facet_grid(sex ~ education_factor)

#we can double check this is correct by using the original demographics data
#covar_df |> 
#  ggplot(aes(x=age, color=sex)) +
#  geom_histogram(aes(fill=sex), binwidth=5) +
#  facet_grid(sex ~ education)
```

Comment

Traditional analyses of accelerometer data focus on the total activity over the day. Using your tidied dataset, aggregate across minutes to create a total activity variable for each participant. Plot these total activities (y-axis) against age (x-axis); your plot should compare men to women and have separate panels for each education level. Include a trend line or a smooth to illustrate differences. Comment on your plot.

Let's make sure we're getting all participants:
```{r}
length(unique(pull(nhanes_df, seqn)))
#length(unique(nhanes_df$seqn))
```


```{r}
nhanes_df |> 
  group_by(seqn, sex, age, education_factor) |> 
  summarize(
    total_activity = sum(MIMS)
  ) |> 
  ggplot(aes(x=age, y=total_activity, color=sex)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = FALSE) +
  facet_grid(education_factor ~ .)
```

Comment

```{r}
#Test with a single person
#nhanes_df |> 
#  filter(seqn==62161) |> 
#  ggplot(aes(x=min, y=MIMS)) +
#  geom_point()

#convert minutes to hours
nhanes_df |> 
  group_by(min, sex, education_factor) |> 
  summarize(
    mean_mims = mean(MIMS, na.rm = TRUE),
    median_mims = median(MIMS, na.rm = TRUE)
  ) |> 
  ggplot(aes(x=min, y=median_mims, color=sex)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se=FALSE) +
  facet_grid(education_factor ~ .)
```















